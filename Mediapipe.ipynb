{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mediapipe.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAuK32r45jHdT0WCEMorZG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scottman625/Tibame-project/blob/main/Mediapipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD0cUxt2x8hX",
        "outputId": "17b5a408-4417-4000-9215-adcd53844017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.9.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 上傳自己要做分析的影片並命名為 \"my_video.mov\""
      ],
      "metadata": {
        "id": "vODWPXlKp8Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose"
      ],
      "metadata": {
        "id": "tv5shDAt0NfX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_angle(a,b,c):\n",
        "    a = np.array(a) # First\n",
        "    b = np.array(b) # Mid\n",
        "    c = np.array(c) # End\n",
        "    \n",
        "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
        "    angle = np.abs(radians*180.0/np.pi)\n",
        "    \n",
        "    if angle >180.0:\n",
        "        angle = 360-angle\n",
        "        \n",
        "    return angle "
      ],
      "metadata": {
        "id": "rTpHCKV_pqfq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('/content/my_video.mov')\n",
        "m1 = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "m2 = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "p1 = cv2.VideoWriter(\"new_video.mp4\", cv2.VideoWriter_fourcc(*'MP4V'), fps,(m1,m2))\n",
        "## Setup mediapipe instance\n",
        "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "    while cap.isOpened():\n",
        "      ret, frame = cap.read()\n",
        "\n",
        "        if ret==True: \n",
        "            # Recolor image to RGB\n",
        "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            image.flags.writeable = False\n",
        "          \n",
        "            # Make detection\n",
        "            results = pose.process(image)\n",
        "        \n",
        "            # Recolor back to BGR\n",
        "            image.flags.writeable = True\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "            \n",
        "            # Extract landmarks\n",
        "            try:\n",
        "                landmarks = results.pose_landmarks.landmark\n",
        "                \n",
        "                # Get coordinates\n",
        "                shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
        "                elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
        "                wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
        "                \n",
        "                # Calculate angle\n",
        "                angle = calculate_angle(shoulder, elbow, wrist)\n",
        "                \n",
        "                # Visualize angle\n",
        "                cv2.putText(image, str(angle), \n",
        "                              tuple(np.multiply(elbow, [m1, m2]).astype(int)), \n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
        "                                    )\n",
        "                          \n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "            \n",
        "            # Render detections\n",
        "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
        "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
        "                                    )               \n",
        "            \n",
        "          \n",
        "            p1.write(image)\n",
        "\n",
        "       \n",
        "        else:\n",
        "          break\n",
        "cap.release()\n",
        "    \n",
        "   "
      ],
      "metadata": {
        "id": "4smTptI0yUrV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "979e896c-7c07-4843-9193-9bc792155492"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e1d54b53a909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmp_pose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_detection_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_tracking_confidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}